# -*- coding: utf-8 -*-
"""Machine Learning Coursework UoN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fYEj93VvV2Y7OVj_ep5LIWp41f_yOlia

# Classification of the IRIS Dataset
"""

# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris

# Load the Iris dataset

url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'
feature_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']
df_iris = pd.read_csv(url, names=feature_names)

# Basic information about the dataset
print("Sample data from the Iris dataset:")
print(df_iris.head())
print("\nDataset information:")
print(df_iris.info())
print("\nDescriptive statistics:")
print(df_iris.describe())

# Visualize the dataset
sns.set(style="ticks")
sns.pairplot(df_iris, hue="class", markers=["o", "s", "D"])
plt.title("Pairplot of Iris Dataset")
plt.show()

# Box plots for each feature
plt.figure(figsize=(12, 6))
for i, feature in enumerate(feature_names[:-1]):
    plt.subplot(2, 2, i + 1)
    sns.boxplot(x="class", y=feature, data=df_iris)
    plt.title(f"{feature} by target")
plt.tight_layout()
plt.show()

# Correlation heatmap
correlation_matrix = df_iris.corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap="YlGnBu")
plt.title("Feature Correlation Heatmap")
plt.show()

"""#Data Preprocessing"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split


# Load the Iris dataset from sklearn

iris = load_iris()
data = pd.DataFrame(data=iris.data, columns=iris.feature_names)
data['target'] = iris.target

#Data Preprocessing and Cleaning

# 1. Check for Missing Values
missing_values = data.isnull().sum()
print("Missing Values:\n", missing_values)

# 2. Standardize the Features (mean = 0, variance = 1)
scaler = StandardScaler()
data.iloc[:, :-1] = scaler.fit_transform(data.iloc[:, :-1])

# 3. Split the Data into Training and Testing Sets
X = data.iloc[:, :-1]
y = data['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""# Validation - For Tuning HyperParameters

##SVM

##Decision Tree

##Multi Layer Perceptron

##Logistic Regression
"""

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns


# Split the data into training and testing sets
# test size here means validation size
X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Define the parameter grid for the SVM
param_grid_SVC = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear']}

# Create the SVM model
svm = SVC()

# Perform grid search with cross-validation
grid_search = GridSearchCV(svm, param_grid_SVC, refit=True, verbose=3, cv=5)
grid_search.fit(X_train_val, y_train_val)

# Print the best parameters
print("Best parameters found: ", grid_search.best_params_)

# Make predictions
y_pred = grid_search.predict(X_test_val)

# Print classification report and confusion matrix
print("Classification Report:")
print(classification_report(y_test_val, y_pred))

print("Confusion Matrix:")
cm = confusion_matrix(y_test_val, y_pred)
sns.heatmap(cm, annot=True, fmt='d')
plt.show()

from sklearn.tree import DecisionTreeClassifier

# Split the data into training and testing sets
# test size here means validation size
X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Define the parameter grid for the Decision Tree
param_DT = {'criterion': ['gini', 'entropy'], 'max_depth': [3, 4, 5, 6, 7, 8, 9]}

# Create the Decision Tree model
dt = DecisionTreeClassifier()

# Perform grid search with cross-validation
grid_search = GridSearchCV(dt, param_DT, refit=True, verbose=3, cv=5)
grid_search.fit(X_train_val, y_train_val)

# Print the best parameters
print("Best parameters found: ", grid_search.best_params_)

# Make predictions
y_pred = grid_search.predict(X_test_val)

# Print classification report and confusion matrix
print("Classification Report:")
print(classification_report(y_test_val, y_pred))

print("Confusion Matrix:")
cm = confusion_matrix(y_test_val, y_pred)
sns.heatmap(cm, annot=True, fmt='d')
plt.show()

from sklearn.neural_network import MLPClassifier


# Split the data into training and testing sets\
# test size here means validation size
X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Define the parameter grid for Multilayer Perceptron
param_MLPC = {
    'hidden_layer_sizes': [(50,),(100,),(50,50)],
    'activation': ['logistic', 'tanh', 'relu'],
    'solver': ['adam'],
    'alpha': [0.0001, 0.05],
    'learning_rate': ['constant','adaptive']
}

# Create the Multilayer Perceptron model
mlp = MLPClassifier(max_iter=1000)

# Perform grid search with cross-validation

grid_search = GridSearchCV(mlp, param_MLPC, refit=True, verbose=3, cv=5)
grid_search.fit(X_train_val, y_train_val)

# Print the best parameters
print("Best parameters found: ", grid_search.best_params_)

# Make predictions
y_pred = grid_search.predict(X_test_val)

# Print classification report and confusion matrix
print("Classification Report:")
print(classification_report(y_test_val, y_pred))

print("Confusion Matrix:")
cm = confusion_matrix(y_test_val, y_pred)
sns.heatmap(cm, annot=True, fmt='d')
plt.show()

from sklearn.linear_model import LogisticRegression

# Split the data into training and testing sets
# test size here means validation size
X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Define the parameter grid for Logistic Regression
param_LR = {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l2']}

# Create the Logistic Regression model
lr = LogisticRegression(max_iter=1000, solver='lbfgs')

# Perform grid search with cross-validation
grid_search = GridSearchCV(lr, param_LR, refit=True, verbose=3, cv=5)
grid_search.fit(X_train_val, y_train_val)

# Print the best parameters
print("Best parameters found: ", grid_search.best_params_)

# Make predictions
y_pred = grid_search.predict(X_test_val)

# Print classification report and confusion matrix
print("Classification Report:")
print(classification_report(y_test_val, y_pred))

print("Confusion Matrix:")
cm = confusion_matrix(y_test_val, y_pred)
sns.heatmap(cm, annot=True, fmt='d')
plt.show()

"""#Classification using all four Classifiers with K-Fold Cross Validation"""

import numpy as np
from sklearn.model_selection import cross_val_score, KFold



# Create and evaluate models using K-fold cross-validation
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# Logistic Regression
lr_model = LogisticRegression(max_iter=1000, C=10, penalty='l2')
lr_scores = cross_val_score(lr_model, X_train, y_train, cv=kfold, scoring='accuracy')
print("Logistic Regression Mean Accuracy:", np.mean(lr_scores))

# Support Vector Machine
svm_model = SVC(C=100, gamma=0.01, kernel='rbf')
svm_scores = cross_val_score(svm_model, X_train, y_train, cv=kfold, scoring='accuracy')
print("SVM Mean Accuracy:", np.mean(svm_scores))

# Decision Tree
dt_model = DecisionTreeClassifier(criterion='gini', max_depth = 3)
dt_scores = cross_val_score(dt_model, X_train, y_train, cv=kfold, scoring='accuracy')
print("Decision Tree Mean Accuracy:", np.mean(dt_scores))

# Multilayer Perceptron (Neural Network)
mlp_model = MLPClassifier(max_iter=1000, activation='logistic', alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate='constant', solver='adam')
mlp_scores = cross_val_score(mlp_model, X_train, y_train, cv=kfold, scoring='accuracy')
print("MLP Mean Accuracy:", np.mean(mlp_scores))

# Create a bar plot to visualize K-fold cross-validation results
models = ['Logistic Regression', 'SVM', 'Decision Tree', 'MLP']
mean_accuracies = [np.mean(lr_scores), np.mean(svm_scores), np.mean(dt_scores), np.mean(mlp_scores)]

plt.figure(figsize=(10, 6))
plt.bar(models, mean_accuracies, color='skyblue')
plt.title('K-Fold Cross-Validation Mean Accuracies')
plt.xlabel('Models')
plt.ylabel('Mean Accuracy')
plt.ylim(0.8, 1.0)
plt.show()

# Compare the performance of the models on the test set
lr_model.fit(X_train, y_train)
lr_test_accuracy = lr_model.score(X_test, y_test)

svm_model.fit(X_train, y_train)
svm_test_accuracy = svm_model.score(X_test, y_test)

dt_model.fit(X_train, y_train)
dt_test_accuracy = dt_model.score(X_test, y_test)

mlp_model.fit(X_train, y_train)
mlp_test_accuracy = mlp_model.score(X_test, y_test)

print("\nTest Set Accuracy:")
print("Logistic Regression:", lr_test_accuracy)
print("SVM:", svm_test_accuracy)
print("Decision Tree:", dt_test_accuracy)
print("MLP:", mlp_test_accuracy)

"""#Regression using the Wine Quality Dataset

##Visualisation
"""

!pip install ucimlrepo

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_openml

# Fetch the Wine Quality Dataset from OpenML
# wine_data = fetch_openml(data_id=187)

# # Convert the data and target to a DataFrame
# wine_df = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)
# wine_df['quality'] = wine_data.target
# print(wine_data.target)

url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'

data = pd.read_csv(url, sep=';')

# Extract the features and target variable
X = data.drop('quality', axis=1)
y = data['quality']

# Basic information about the dataset
print(X.head())
print(X.info())
print(X.describe())

# Pairplot for data visualization
sns.pairplot(data, hue="quality", palette="coolwarm")
plt.title("Pairplot of Wine Quality Dataset")
plt.show()

# Box plots for each feature
plt.figure(figsize=(12, 6))
for feature in X:  # Exclude the 'quality' column
    sns.boxplot(x="quality", y=feature, data=data, palette="coolwarm")
    plt.title(f"{feature} by quality")
    plt.show()

"""## Data Preprocessing"""

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
# Data Preprocessing and Cleaning

# 1. Check for Missing Values
missing_values = data.isnull().sum()
print("Missing Values:\n", missing_values)

# 2. Standardize the Features (mean = 0, variance = 1)
scaler = StandardScaler()
data.iloc[:, :-1] = scaler.fit_transform(data.iloc[:, :-1])
print(data.iloc[:, :-1])
# 3. Split the Data into Training and Testing Sets
X = data.iloc[:, :-1]
y = y
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""# All four Regression Models

"""

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

# Split the data into training and testing sets
X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Define the parameter grid for SVM
param_SVR = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear']}

# Create the SVM model
svm = SVR()

# Perform grid search with cross-validation
grid_search = GridSearchCV(svm, param_SVR, refit=True, verbose=3, cv=5)
grid_search.fit(X_train_val, y_train_val)

# Print the best parameters
print("Best parameters found: ", grid_search.best_params_)

# Make predictions
y_pred = grid_search.predict(X_test_val)

# Calculate the model performance
mse = mean_squared_error(y_test_val, y_pred)
r2 = r2_score(y_test_val, y_pred)

# Print the performance metrics
print(f"Mean Squared Error: {mse}")
print(f"R2 Score: {r2}")

from sklearn.tree import DecisionTreeRegressor

# Split the data into training and testing sets
X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Define the parameter grid for Decision Tree Regression
param_DT = {'max_depth': [3, 5, 7]}

# Create the Decision Tree Regression model
dt = DecisionTreeRegressor()

# Perform grid search with cross-validation
grid_search = GridSearchCV(dt, param_DT, refit=True, verbose=3, cv=5)
grid_search.fit(X_train_val, y_train_val)

# Print the best parameters
print("Best parameters found: ", grid_search.best_params_)

# Make predictions
y_pred = grid_search.predict(X_test_val)

# Calculate the model performance
mse = mean_squared_error(y_test_val, y_pred)
r2 = r2_score(y_test_val, y_pred)

# Print the performance metrics

print(f"Mean Squared Error: {mse}")
print(f"R2 Score: {r2}")

from sklearn.linear_model import LinearRegression

# Split the data into training and testing sets
X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Create the Linear Regression model
lr = LinearRegression()

# Fit the model to the training data
lr.fit(X_train_val, y_train_val)

# Make predictions
y_pred = lr.predict(X_test_val)

# Calculate the model performance
mse = mean_squared_error(y_test_val, y_pred)
r2 = r2_score(y_test_val, y_pred)

# Print the performance metrics
print(f"Mean Squared Error: {mse}")
print(f"R2 Score: {r2}")

from sklearn.neural_network import MLPRegressor

# Split the data into training and testing sets
X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Define the parameter grid for MLPRegressor
param_MLPR = {
    'hidden_layer_sizes': [(50,),(100,),(50,50)],
    'activation': ['logistic', 'tanh', 'relu'],
    'solver': ['adam'],
    'alpha': [0.0001, 0.05],
    'learning_rate': ['constant','adaptive']
}

# Create the MLPRegressor model
mlp = MLPRegressor(max_iter=1000)

# Perform grid search with cross-validation
grid_search = GridSearchCV(mlp, param_MLPR, refit=True, verbose=3, cv=5)
grid_search.fit(X_train, y_train)

# Print the best parameters
print("Best parameters found: ", grid_search.best_params_)

# Make predictions
y_pred = grid_search.predict(X_test_val)

# Calculate the model performance
mse = mean_squared_error(y_test_val, y_pred)
r2 = r2_score(y_test_val, y_pred)

# Print the performance metrics
print(f"Mean Squared Error: {mse}")
print(f"R2 Score: {r2}")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold, cross_val_score, train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error

# Split the data into features (X) and target (y)

X = data.iloc[:, :-1]
y = y

# Define the regression models
linear_reg = LinearRegression()
svr = SVR(C=1, gamma=0.1, kernel='rbf')
dt_regressor = DecisionTreeRegressor(max_depth=3)
mlp_regressor = MLPRegressor(max_iter=1000, activation='relu', alpha=0.05, hidden_layer_sizes=(100,), learning_rate='adaptive', solver='adam')

# Create a list of models
models = [linear_reg, svr, dt_regressor, mlp_regressor]
model_names = ["Linear Regression", "Support Vector Machine", "Decision Tree", "MLP Neural Network"]

# Apply K-fold cross-validation (K is determined by the number of splits)
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

mse_scores = []

for model, name in zip(models, model_names):
    mse = -cross_val_score(model, X_test, y_test, cv=kfold, scoring='neg_mean_squared_error')
    mse_scores.append(mse)
    print(f"{name} MSE: {np.mean(mse)}")

# Visualize the K-fold cross-validation results
plt.figure(figsize=(10, 6))
plt.boxplot(mse_scores, labels=model_names)
plt.title("K-Fold Cross-Validation Results (MSE)")
plt.ylabel("Mean Squared Error (MSE)")
plt.xticks(rotation=45)
plt.show()

"""Parameter optimization / hyperparameter tuning allows us to find a set of best hyperparameters in order to build the most optimized model for machine learning or deep learning to attain the best accuracy.

Here we are using grid search based approach that extensively runs the algorithm again and again for the set of parameters the user wants to tune from and then the grid search algorithm runs for all possible permutations of the hyperparameters in order to find the best heperparameters.
"""



